print("Running 'processing_mitomaster_output_files' script...")

# IMPORT MODULES
# --------------

print('Importing modules...')

import easygui, os, pyreadstat, dask.dataframe as dd, pandas as pd, seaborn as sns, matplotlib.pyplot as plt, \
    numpy as np, glob, scipy.stats as stats, warnings

warnings.filterwarnings(action='ignore')

# ----------------------------------------------------------------------------------------------------------------------

# EASYGUI POP-UP WITH REQUIREMENTS

# use easygui to allow user to select the folder where they have saved the data for this script
source_dir_of_required_files = easygui.diropenbox(msg="Welcome! For this script to run, please select the "
                                                      "\"Required_files\" folder that was downloaded together with "
                                                      "this script", title="Select folder")

msg = ("Before proceeding, please ensure the following:\n\n"
       "1. You have run  the 'making_a_mitomaster_upload_file' script\n\n"
       "2. You have downloaded and saved your mitomaster output files (as instructed) "
       "to a single folder on your computer\n\n"
       "3. You should have saved at least two .csv (i.e. comma delimited) files from mitomaster (one of each of the "
       "following) in the said folder:\n\n"
       "  - A .csv file that contains the word \"var_list\" \n"
       "  - A .csv file that contains the word \"mitomaster\" (all lower case letters) \n\n"
       "4. You have created a .csv file (that contains the words 'sample_info' in the file name) with the details of "
       "your sequenced samples and the following column headers (see example below):\n "
       "'sample' (i.e. name of sample) , 'age', 'sex', 'status' (i.e. case or control)\n\n"
       "              Click \"Continue\" if you have ensured all of the above\n\n")
image = source_dir_of_required_files + "\sample_info_example.png"

title = 'Please Confirm'
if easygui.ccbox(msg, title, image=image):  # show a Continue/Cancel dialog
    pass  # user chose Continue
else:  # user chose Cancel
    exit()


# ----------------------------------------------------------------------------------------------------------------------
# FUNCTIONS
# ---------

# Write a for function to do fisher's exact test's comparing the number of cases and controls with and without variants across the
# mitochondrial genome

def fishers_test(df_list, row_list):
    """"
    Applies the fishers exact function to every dataframe in a list and adds the odd-ratios and p-values to an a pandas dataframe.
    It also requires a list with the names of the dataframes in the same order as given in the list of dataframes
    """

    # make an empty dataframe to append odds ratios and p-values to (generated by Fisher's exact tests)
    fishers_df = pd.DataFrame(columns=['odds_ratio', 'fishers_p_value'])

    for df in df_list:
        odds_ratio, p_value = stats.fisher_exact(df)
        # append values to empty df
        fishers_df = fishers_df.append({'odds_ratio': odds_ratio, 'fishers_p_value': p_value}, ignore_index=True)

    # add df names from fisher's exact test to the fisher'df
    fishers_df['Fisher_test_DataFrame'] = row_list
    # re-arrange columns in df
    fishers_df = fishers_df.reindex(columns=['Fisher_test_DataFrame', 'odds_ratio', 'fishers_p_value'])

    return fishers_df


def save_xls(dict_df, path):
    """
    Save a dictionary of dataframes to an excel file, with each dataframe as a separate sheet
    """
    writer = pd.ExcelWriter(path)
    for key in dict_df:
        dict_df[key].to_excel(excel_writer=writer, sheet_name=key, index=False)

    writer.save()


def barplot_labels(df):
    """ Function adds value labels to the top of the barplot """
    for p in df.patches:
        df.annotate(np.round(p.get_height(), decimals=2), (p.get_x() + p.get_width() / 2., p.get_height()),
                    ha='center', va='center', xytext=(0, 5), textcoords='offset points', fontsize=11)

    return df


def percentage(df, col_name):
    """ Adds a column to the input dataframe with the percentage of individuals from each status group (case or control)
    who have a particular variant"""

    df['percentage'] = pd.np.where(df.status.str.contains('control'),
                                   ((df[col_name]) / count_controls_in_analysis * 100).round(2),
                                   pd.np.where(df.status.str.contains('case'),
                                               ((df[col_name]) / count_cases_in_analysis * 100).round(2), 'NaN'))
    df = df.astype({'percentage': float})
    return df


def rare_variants_df(dataframe, rare_GB_haplo_col, sample_list, sample_info):
    ''' Check if given sample(elem) exists in df or not. Input a df, sample_list and df with the sample info.
        The function returns a df which includes all samples not in the original df which was checked'''
    resultDict = {}
    samples_not_in_df = []

    dataframe = dataframe.drop(dataframe[dataframe[rare_GB_haplo_col] == 0].index, inplace=False)

    # Iterate over the list of elements one by one
    for elem in sample_list:
        # Check if the element exists in dataframe values
        if elem in dataframe.values:
            resultDict[elem] = True
        else:
            resultDict[elem] = False
    # If samples are not in df, include them in a list
    for (sample_name, result) in resultDict.items():
        if result == False:
            samples_not_in_df.append(sample_name)

    # make a df with the samples and their sample details
    sample_not_in_df_dict = {'sample': samples_not_in_df}
    sample_not_in_df = pd.DataFrame(sample_not_in_df_dict, columns=['sample'])
    sample_not_in_df_details = sample_not_in_df.merge(sample_info, on='sample')
    # append new df with samples not in the original df and their corresponding details to the original df
    dataframe = dataframe.append(sample_not_in_df_details, sort=False)
    # replace nan values with 0
    dataframe = dataframe.fillna(0)

    # Check whether a df has a type of variant or not, and add a variant column
    # add rare variant column
    def individuals_with_var(dataframe):
        ''' Check if sample has a variant in the df.'''
        if dataframe['pos'] == 0:
            val = 'no'
        else:
            val = 'yes'
        return val

    dataframe = dataframe.assign(sample_has_var=dataframe.apply(individuals_with_var, axis=1))

    return dataframe


def appended_df(dataframe, sample_list, sample_info):
    ''' Check if given sample(elem) exists in df or not. Input a df, sample_list and df with the sample info.
        The function returns a df which includes all samples not in the ordinal df which was checked'''
    resultDict = {}
    samples_not_in_df = []

    # Iterate over the list of elements one by one
    for elem in sample_list:
        # Check if the element exists in dataframe values
        if elem in dataframe.values:
            resultDict[elem] = True
        else:
            resultDict[elem] = False
    # If samples are not in df, include them in a list
    for (sample_name, result) in resultDict.items():
        if result == False:
            samples_not_in_df.append(sample_name)

    # make a df with the samples and their sample details
    sample_not_in_df_dict = {'sample': samples_not_in_df}
    sample_not_in_df = pd.DataFrame(sample_not_in_df_dict, columns=['sample'])
    sample_not_in_df_details = sample_not_in_df.merge(sample_info, on='sample')
    # append new df with samples not in the original df and their corresponding details to the original df
    dataframe = dataframe.append(sample_not_in_df_details, sort=False)
    # replace nan values with 0
    dataframe = dataframe.fillna(0)

    return dataframe


# calculate count of variants for cases and controls

def variant_count(dataframe, mtDNA_region):
    '''Function counts the number of individuals per variant count group'''

    # replace yes with 1, no with 0
    dataframe['sample_has_var'].mask(dataframe['sample_has_var'] == 'yes', 1, inplace=True)
    dataframe['sample_has_var'].mask(dataframe['sample_has_var'] == 'no', 0, inplace=True)
    # calculate count of variants per person
    var_count_per_person = dataframe.groupby(['sample', 'haplogrep_haplogroup', 'status']) \
        ['sample_has_var'].sum().reset_index(name='variant_count')

    # apply variant_counts_grouped_by_counts(dataframe, counting_column_name) function
    grouped_var_count_per_person = variant_counts_grouped_by_counts(var_count_per_person, 'variant_count')
    grouped_var_count_per_person.loc[:, 'mtDNA region'] = mtDNA_region
    grouped_var_count_per_person.loc[:, 'variant_count'] = pd.to_numeric(grouped_var_count_per_person['variant_count'],
                                                                         downcast='integer')

    return grouped_var_count_per_person


def rare_var_counts_grouped_by_counts(dataframe, rare_var_col_count_name):
    """Function that counts the number of  variants per status group and adds rows for when cases
    have a unique count of rare variants but controls don't, and vice versa.
    It returns df with individuals who have rare variants and a df with counts of rare variants"""

    def rare_var_count(dataframe, rare_var_col_count_name):
        rare_var_count = (dataframe.groupby(['sample', 'haplogrep_haplogroup', 'status'])
                          .apply(lambda x: (x['sample_has_var'] == 'yes').sum())
                          .reset_index(name=rare_var_col_count_name))
        return rare_var_count

    # apply function
    rare_var_count = rare_var_count(dataframe, rare_var_col_count_name)

    # Identify individuals with rare variants
    rare_var_individuals_filter = rare_var_count[rare_var_col_count_name] != 0
    rare_var_individuals = rare_var_count[rare_var_individuals_filter]

    # groupby count of rare variants and status
    rare_var_count = (rare_var_count.groupby([rare_var_col_count_name])['status']
                      .value_counts().to_frame('count_of_individuals'))
    # reset index
    rare_var_count = rare_var_count.reset_index()

    # Add rows for when cases have a unique count of rare variants but controls don't, and vice versa
    unique_counts = rare_var_count.drop_duplicates(subset=rare_var_col_count_name, keep=False)
    unique_counts = unique_counts.replace({'status': {'case': 'A', 'control': 'B'}})
    unique_counts = unique_counts.replace({'status': {'A': 'control', 'B': 'case'}})
    # make all values in count_of_individuals column == 0
    unique_counts.loc[:, 'count_of_individuals'] = 0
    # append new df to original df
    rare_var_count = rare_var_count.append(unique_counts, sort=False)
    # sort status column alphabetically
    rare_var_count = rare_var_count.sort_values('status')
    # sort rare var column numerically
    rare_var_count = rare_var_count.sort_values(rare_var_col_count_name)
    # reset the index to start at 0
    rare_var_count.index = np.arange(0, len(rare_var_count))
    # add a column giving the percentage of each status group with rare variants using previously
    # defined percentage function
    rare_var_count = percentage(rare_var_count, 'count_of_individuals')

    return rare_var_individuals, rare_var_count


# function that makes a df that can be used for the fishers exact test and to plot graphs

def fishers_exact_df_and_graph_df(dataframe, new_name_of_rare_variant_col, rare_variant_locus):
    """Input rare variant df, the name of the new rare_variant_col and the locus of the rare variant as strings
    eg.new_name_of_rare_variant_col = 'sample_has_rare_haplo_nonsyn_var', rare_variant_locus= 'coding'.

    This function returns two dfs: cross_tab_dataframe_filled and rare_var_graph_df
    One that can be used for a fishers exact test and  one that can be used to make a graph"""

    dataframe = dataframe.drop_duplicates(subset='sample', keep='first')
    # rename rare_variant col
    dataframe = dataframe.rename(columns={'sample_has_var': new_name_of_rare_variant_col})
    cross_tab_dataframe = pd.crosstab(dataframe['status'], dataframe[new_name_of_rare_variant_col])

    # write a function to check if crosstabs have columns yes and no, if not, add missing col

    def check_crosstab_col(cross_tab_dataframe):
        ''' Check if given element exists in columns of the df or not. Input a df.
            It returns your edited input df'''
        resultDict = {}
        columns_list = [1, 0]
        columns_not_in_df = []
        # Iterate over the list of elements one by one
        for elem in columns_list:
            # Check if the element exists in cross_tab_dataframe columns
            if elem in cross_tab_dataframe.columns:
                resultDict[elem] = True
            else:
                resultDict[elem] = False
        # If columns are not in df, include them in a list
        for (column_name, result) in resultDict.items():
            if result == False:
                # make a new col
                cross_tab_dataframe.loc[:, column_name] = '0'

        # Returns new df with filled yes, no columns
        return cross_tab_dataframe

    # apply check_crosstab_col function to original df
    cross_tab_dataframe_filled = check_crosstab_col(cross_tab_dataframe)
    # rename columns
    cross_tab_dataframe_filled = cross_tab_dataframe_filled.rename(columns={1: 'yes', 0: 'no'}, inplace=False)

    # make df for graphs
    def rare_var_graph_df(cross_tab_dataframe_filled, rare_variant_locus):
        # make a copy of df
        cross_tab_dataframe_graph = cross_tab_dataframe_filled.copy()
        # add a new column with rare varint name e.g. rare_CI
        cross_tab_dataframe_graph.loc[:, 'rare_var'] = rare_variant_locus
        # reset index
        cross_tab_dataframe_graph = cross_tab_dataframe_graph.reset_index().rename_axis(None, axis='columns')
        return cross_tab_dataframe_graph

    # apply rare_var_graph function
    cross_tab_dataframe_graph = rare_var_graph_df(cross_tab_dataframe_filled, rare_variant_locus)

    def percentage(cross_tab_dataframe_graph):
        """adds a column to the input dataframe with the percentage of individuals from each status group
         (case or control) who have a particular variant"""
        cross_tab_dataframe_graph = cross_tab_dataframe_graph.astype({'yes': int})

        cross_tab_dataframe_graph['percentage'] = pd.np.where(cross_tab_dataframe_graph.status.str.contains('control'),
                                                              ((cross_tab_dataframe_graph[
                                                                  'yes']) / count_controls_in_analysis * 100).round(2),
                                                              pd.np.where(
                                                                  cross_tab_dataframe_graph.status.str.contains('case'),
                                                                  ((cross_tab_dataframe_graph['yes'])
                                                                   / count_cases_in_analysis * 100).round(2), 'NaN'))
        return cross_tab_dataframe_graph

    # apply percentage function to cross_tab_dataframe_graph df
    cross_tab_dataframe_graph = percentage(cross_tab_dataframe_graph)

    return cross_tab_dataframe_filled, cross_tab_dataframe_graph


# MUTPRED/ pathogenicity scoring
# ------------------------------


# write a function that calculates the pathogenicity score per person and the count of scored variants per person

def pathogenic_scoring(dataframe, pathogenic_cutoff_value, pathogenic_col_name):
    """Function calculates the variant load (sum of all variants above a defined threshold) per person, and returns a
    df with the variant load per person and the count of pathogenic-scored variants per person"""

    # calculate pathogenic scores for cases and controls
    def variant_load(dataframe, pathogenic_cutoff_value, pathogenic_col_name):
        pathogenic_scores_per_person = dataframe.groupby(['sample', 'haplogrep_haplogroup', 'status']) \
            .apply(
            lambda x: x[x[pathogenic_col_name] > pathogenic_cutoff_value][pathogenic_col_name].sum()).reset_index(
            name='variant_load')
        return pathogenic_scores_per_person

    # apply function
    pathogenic_scores_per_person = variant_load(dataframe, pathogenic_cutoff_value, pathogenic_col_name)
    # Add samples without mutpred variant loads by applying the 'appended' function.
    pathogenic_scores_per_person = appended_df(pathogenic_scores_per_person, sample_list, sample_info)

    # calculate pathogenic count of variants for cases and controls

    pathogenic_count_per_person = dataframe.groupby(['sample', 'haplogrep_haplogroup', 'status']) \
        [pathogenic_col_name].apply(lambda x: (x > pathogenic_cutoff_value).sum()).reset_index(
        name='pathogenic_count')

    # Add samples without mutpred variants by applying the 'appended' function.
    pathogenic_count_per_person = appended_df(pathogenic_count_per_person, sample_list, sample_info)

    # return two dataframes

    return pathogenic_scores_per_person, pathogenic_count_per_person


# -----------------------------------------------------------------------------------------------------------------
def variant_counts_grouped_by_counts(dataframe, counting_column_name):
    """Function that counts the number of pathogenic scored variants per status group and adds rows for when cases
    have a unique count of scored variants but controls don't, and vice versa"""
    # groupby count of mutpred variants and status
    dataframe = dataframe.groupby([counting_column_name])['status'] \
        .value_counts().to_frame('count_of_individuals')
    # reset index
    dataframe = dataframe.reset_index()

    # Add rows for when cases have a unique count of mutpred-scored variants but controls don't, and vice versa
    unique_counts = dataframe.drop_duplicates(subset=counting_column_name, keep=False)
    unique_counts = unique_counts.replace({'status': {'case': 'A', 'control': 'B'}})
    unique_counts = unique_counts.replace({'status': {'A': 'control', 'B': 'case'}})
    # make all values in count_of_individuals column == 0
    unique_counts.loc[:, 'count_of_individuals'] = 0
    # append new df to original df
    dataframe = dataframe.append(unique_counts, sort=False)
    # sort status column alphabetically
    dataframe = dataframe.sort_values('status')
    # sort mutpred_count column numerically
    dataframe = dataframe.sort_values(counting_column_name)
    # reset the index to start at 0
    dataframe.index = np.arange(0, len(dataframe))
    # add a column giving the percentage of each status group with variants using previously
    # defined percentage function
    dataframe = percentage(dataframe, 'count_of_individuals')

    return dataframe


def rare_var_counts_grouped_by_SNP(dataframe):
    """Function that counts the number of rare variants per status group and adds rows for when cases
    have a unique count of the rare variant but controls don't, and vice versa.
    It returns df with counts of rare variants, grouped by the SNP"""

    # groupby count of rare variants and status
    rare_var_count = dataframe.groupby(['SNP'])['status'].value_counts().to_frame(
        'count_of_individuals').reset_index()

    # Add rows for when cases have a unique count of rare variants but controls don't, and vice versa
    unique_counts = rare_var_count.drop_duplicates(subset='SNP', keep=False)
    unique_counts = unique_counts.replace({'status': {'case': 'A', 'control': 'B'}})
    unique_counts = unique_counts.replace({'status': {'A': 'control', 'B': 'case'}})
    # make all values in count_of_individuals column == 0
    unique_counts.loc[:, 'count_of_individuals'] = 0
    # append new df to original df
    rare_var_count = rare_var_count.append(unique_counts, sort=False)
    # convert column to string
    rare_var_count = rare_var_count.astype({'SNP': str})
    # sort columns alphabetically
    rare_var_count = rare_var_count.sort_values(['SNP', 'status'])
    # reset the index to start at 0
    rare_var_count.index = np.arange(0, len(rare_var_count))
    # add a column giving the percentage of each status group with rare variants using previously
    # defined percentage function
    rare_var_count = percentage(rare_var_count, 'count_of_individuals')
    # replace 0 in 'SNP' column with a string: 'No SNP'
    rare_var_count.loc[:, 'SNP'] = rare_var_count.replace('0', 'No_SNP')

    return rare_var_count


# PATHOGENICITY FILE
# ------------
# use path chosen by user to the "Required_files" folder to open the file
pathogenic_variants_file_location = source_dir_of_required_files + "\mutpred_mtoolbox_apogee_cheat_sheet.csv"

pathogenic_variants_list = pd.read_csv(pathogenic_variants_file_location,
                                       sep=';')
for col in ['MutPred', 'apogee_score', 'mtoolbox_ds']:
    pathogenic_variants_list[col] = pd.to_numeric(pathogenic_variants_list[col], downcast='float').fillna(0)

# MTDNA SERVER HAPLOGROUPS
# ------------------------

# use easygui to allow user to select the folder with their haplogroup.txt files generated by mtDNA-Server
source_dir_of_mtdnaserver_variant_files = easygui.diropenbox(msg='Please select the folder in which you have saved '
                                                                 'all your mtDNA-Server "Haplogroup.txt" files',
                                                             title='Select a folder')

os.chdir(source_dir_of_mtdnaserver_variant_files)


# Read all haplogroup.txt files into one dataframe
all_haplogroup_files = glob.glob(r'*haplogroups*.txt')
haplogrep = pd.concat((pd.read_csv(f, sep='\t') for f in all_haplogroup_files))
# remove _rCRS from sample name if input files were fastq files
haplogrep['SampleID'] = haplogrep['SampleID'].str.split('_rCRS', expand=True)
# split Polymorphisms column after ')'
haplogrep['Polymorphisms'] = haplogrep['Polymorphisms'].str.rsplit(")")
# expand the Polymorphisms column into individual rows so that every SNP is on a new row
haplogrep = (haplogrep.set_index(['SampleID', 'Range', 'Haplogroup', 'Quality'])['Polymorphisms']
             .astype(str)
             .str.split(',', expand=True)
             .stack()
             .reset_index(level=-1, drop=True)
             .reset_index(name='Polymorphisms'))
# replace brackets
haplogrep['Polymorphisms'] = haplogrep['Polymorphisms'].str.replace(r"[(\)]", "")
# replace [] brackets
haplogrep['Polymorphisms'] = haplogrep['Polymorphisms'].str.replace(r"[[\]]", "")
# replace [] brackets
haplogrep['Polymorphisms'] = haplogrep['Polymorphisms'].str.replace(r"['\']", "")
# remove white space before value in column
haplogrep['Polymorphisms'] = haplogrep['Polymorphisms'].str.lstrip()
# split polymorphism column into two
haplogrep[['Polymorphisms', 'Type']] = haplogrep['Polymorphisms'].str.split(' ', 1, expand=True)
# replace 'yes' in Type column with 'haplogroup_defining'
haplogrep['Type'] = haplogrep['Type'].str.replace(r"yes", r"haplogroup_defining")
# drop duplicate rows
haplogrep = haplogrep.drop_duplicates()
# drop rows with 'no'
haplogrep = haplogrep[haplogrep.Type != 'no']
# drop empty rows
haplogrep = haplogrep.dropna(subset=['Type'])
# rename columns
haplogrep.columns = ['sample', 'range', 'haplogrep_haplogroup', 'haplogroup_quality', 'allele',
                     'phylotree_variant_type']
#convert haplogroup_quality column to floats
haplogrep['haplogroup_quality'] = haplogrep['haplogroup_quality'].astype(float)

# make a file with just sample names and haplogroups assigned by Haplogrep 2
haplogrep_haplogroups = haplogrep[['sample', 'haplogrep_haplogroup', 'haplogroup_quality']]
# drop duplicate and individuals without L haplogroups
haplogrep_haplogroups = haplogrep_haplogroups.drop_duplicates(subset='sample', keep='first')

# haplogrep_haplogroups_only_L = haplogrep_haplogroups[haplogrep_haplogroups['haplogrep_haplogroup'].str.contains('L', na=False)]
# # save as xlsx file
# haplogrep_haplogroups_only_L.to_excel(r'C:/Users/Mi/Projects/mtDNA_NGS/SU/mitomaster_files/output/haplogrep_haplogroups.xlsx',
#                                index=False)

# add new column that can be used for merging haplogroup and mitomaster dataframes
haplogrep['haplo_merge_ref'] = haplogrep["sample"] + '_' + haplogrep["allele"]
# rearrange columns and drop columns not needed
haplogrep = haplogrep[['haplo_merge_ref', 'phylotree_variant_type']]


# PHYLOTREE DATA

# use path chosen by user to the "Required_files" folder to open the file
phylotree_file_location = source_dir_of_required_files + "\phylotree_17.txt"
# import Phylotree.txt file
phylotree = pd.read_csv(phylotree_file_location, sep='\t', engine='python')

# MITOMAP HAPLOGRUOP MARKER DATA
# ------------------------------

# These are variants with haplogroup frequencies >80% on Mitomap.

# use path chosen by user to the "Required_files" folder to open the file
mitomap_haplo_markers_file_location = source_dir_of_required_files + "\mitomap_haplogroup_markers_80%.csv"
# import mitomap_haplogroup_markers_80%.csv file
mitomap_haplo_markers = pd.read_csv(mitomap_haplo_markers_file_location, sep=',')

# MITOMASTER OUTPUT FILE CLEANUP
# ------------------------------

# use easygui to allow user to select the folder with their mitomaster_output files
source_dir_of_mitomaster_files = easygui.diropenbox(msg='Please select the folder in which you have saved '
                                                        'all your Mitomaster input and output files', title='Select a folder')

# change the directory to the one selected by the user

os.chdir(source_dir_of_mitomaster_files)

# check if the selected directory contains *mitomaster*.csv files

# if there are no mitomaster files print error message and exit
if len(glob.glob('*mitomaster*.csv')) == 0:
    # bring up error message asking the user to double check whether they have *mitomaster*.csv files in the selected folder.
    easygui.msgbox(msg='OOPS. Looks like there aren\'t any mitomaster files in your selected folder\n\n'
                       'Please check:\n\n'
                       '1. That you have selected the correct folder\n\n'
                       '2. That your mitomaster output files (saved from MitoMaster) are .csv files and are named '
                       'correctly'
                       'Once you have done this, try re-running the script\n\n',
                   title="ERROR: We couldn't find your files!")

    exit()  # exit if the user has chosen the wrong folder



# else make one dataframe from individual mitomaster*.csv files
else:

    # Read all mitomaster.csv files into one dataframe
    all_mitomaster_files = glob.glob(source_dir_of_mitomaster_files + '\*mitomaster*.csv')
    mitomaster = pd.concat((pd.read_csv(f) for f in all_mitomaster_files))

mitomaster.columns = \
    ['sample', 'pos', 'Query Position', 'ref',
     'var', 'mut_type', 'locus', 'other', 'GB_FL_freq%',
     'GB_FL_seq', 'haplogroup', 'Freq % in haplo', 'lit_refs',
     'conservation%', 'patient_report']

# split "Freq % in haplo" column into a freq and a fraction
mitomaster[['haplo_freq%', 'haplo_seq']] = mitomaster["Freq % in haplo"].str.split("(", n=1, expand=True)
mitomaster['haplo_seq'] = mitomaster['haplo_seq'].str.split(")", n=1, expand=True)
# split "GB_FL_freq%" to drop (CR): the control region sequences
mitomaster['GB_FL_freq%'] = mitomaster['GB_FL_freq%'].str.split('%', n=1, expand=True)
# split "GB_FL_seq" to drop (CR)
mitomaster['GB_FL_seq'] = mitomaster['GB_FL_seq'].str.split('(', n=1, expand=True)
# split "GB_FL_seq" to drop (CR)
mitomaster['conservation%'] = mitomaster['conservation%'].str.split("%", n=1, expand=True)
# convert haplofreq and genbank freq to floats
mitomaster = mitomaster.astype({'haplo_freq%': float, 'GB_FL_freq%': float, 'conservation%': float})
# Add SNP column
mitomaster['SNP'] = mitomaster['pos'].astype(str) + mitomaster['ref'] + '>' + mitomaster['var']
# add rare haplogroup and genbank variant column
# If variant is rare (freq <0.1% ) assign variant a '1', else, assign variant a '0'
mitomaster.loc[mitomaster['haplo_freq%'] < 0.1, 'rare_haplo'] = 1
mitomaster.loc[mitomaster['GB_FL_freq%'] < 0.1, 'rare_GB'] = 1
# Fill NAN values in rare columns with 0
mitomaster[['rare_haplo', 'rare_GB']] = mitomaster[['rare_haplo', 'rare_GB']].fillna(0)
# add columns for pathogencity scores using merge: Keep every row in the left dataframe.
mitomaster = pd.merge(mitomaster, pathogenic_variants_list, on='SNP', how='left')
# Fill NAN values in pathogenicity score columns with 0
mitomaster[['MutPred', 'mtoolbox_ds', 'apogee_score']] = mitomaster[['MutPred', 'mtoolbox_ds', 'apogee_score']].fillna(
    0)
# add a column that indicates whether a variant is scored by at least one of the three in silico tools
mitomaster.loc[:, 'scored_variant'] = pd.np.where \
    ((mitomaster.loc[:, 'MutPred'] > 0.5) | (mitomaster.loc[:, 'mtoolbox_ds'] > 0.4311) | (
                mitomaster.loc[:, 'apogee_score'] > 0.5), 1, 0)
# replace blank cells in the lit_refs column with 'NR' for not reported
mitomaster.loc[:,'lit_refs'] = mitomaster.lit_refs.astype(str)
mitomaster.loc[:,'lit_refs'] = mitomaster.replace('nan', '0')


# add new column 'allele', made up of values from 'position' and 'variant' allele columns
mitomaster['allele'] = mitomaster["pos"].map(str) + mitomaster["var"].map(str)
# add new column that can be used for merging haplogroup and mitomaster dataframes
mitomaster['haplo_merge_ref'] = mitomaster["sample"] + '_' + mitomaster["allele"]
# add new columns for local private variants and haplogroup defining variants by merging dataframes
mitomaster = pd.merge(left=mitomaster, right=haplogrep, how='left', on='haplo_merge_ref')
# fill in blanks in haplogrep_haplogroup column
mitomaster = pd.merge(left=mitomaster, right=haplogrep_haplogroups, how='left', on='sample')
# convert 'haplogrep_haplogroup' column to strings
mitomaster['haplogrep_haplogroup'] = mitomaster.haplogrep_haplogroup.astype(str)

# add new column with heteroplasmy levels of variants
# HETEROPLASMY LEVEL DATA

# Read all het_levels.csv files into one dataframe
all_het_level_files = glob.glob(r'*het_levels*.csv')
het_levels = pd.concat((pd.read_csv(f, sep=((',') or (';'))) for f in all_het_level_files))

mitomaster = pd.merge(left=mitomaster, right=het_levels, how='left', on='haplo_merge_ref')
# ask the user which percentage of heteroplasmy  they want to include in their analysis
user_het_level = easygui.enterbox(
    msg="Please enter the heteroplasmy level you'd like to include in your analysis greater than 50.\n\n",
    title='Percentage heteroplasmy cut-off', default='50', strip=True)
user_het_level_int = int(user_het_level)
# filter df for heteroplasmies > user heteroplasmy cut-off percent
mitomaster = mitomaster[mitomaster.loc[:, 'heteroplasmy_%'] > user_het_level_int]

# add new column 'allele', made up of values from 'ref', 'position' and 'variant' allele columns
mitomaster['phylotree_SNP'] = mitomaster["ref"].map(str) + mitomaster["pos"].map(str) + mitomaster["var"].map(str)
# add new columns for variants in the Phylotree_17 database by mergiing dataframes
mitomaster = pd.merge(left=mitomaster, right=phylotree, how='left', on='phylotree_SNP')

# add new columns for variants marked as haplogroup markers on mitomap by mergiing dataframes
mitomaster = pd.merge(left=mitomaster, right=mitomap_haplo_markers, how='left', on='SNP')

# add column for local private variants
# If variant is haplogroup-defining 'common' in a haplogroup other than the one assigned, assign variant a '1', else, assign variant a '0'
mitomaster.loc[mitomaster['phylotree_variant_type'] == 'localPrivateMut', 'common_var'] = 1
# Fill NAN values in rare columns with 0
mitomaster['common_var'] = mitomaster['common_var'].fillna(0)

# use easygui to allow user to select the folder with their sample_info files
source_dir_of_sample_info_files = easygui.diropenbox(msg='Please select the folder in which you have saved '
                                                         'your sample_info file/s', title='Select a folder')

# change the directory to the one selected by the user

os.chdir(source_dir_of_sample_info_files)

# assign samples sex and patient status. Input file with sample details should have the following headings: sample (
# name of sample) , age, sex, status (case or control) in .csv (;-delimited) format
sample_info = dd.read_csv('*sample_info*.csv', sep=((';') or (',')))
# convert to pd DF
sample_info = sample_info.compute()
# reset the index to start at 0
sample_info.index = np.arange(0, len(sample_info))

# merge mitomaster DF with sample info DF
mitomaster_output = pd.merge(mitomaster, sample_info, on='sample', how='left')

# drop all samples not in sample list
mitomaster_output = mitomaster_output.dropna(subset=['status'])

# rename 'haplogroup' column to 'mitomaster_haplogroup'
mitomaster_output = mitomaster_output.rename(columns={'haplogroup': 'mitomaster_haplogroup'})

# make user choose which haplogroups to analyse
haplo_choice_msg = "Which mitochondrial haplogroups would you like to include in the analysis?"
haplogroup_choices = ["African","European"]
reply = easygui.buttonbox(haplo_choice_msg, choices=haplogroup_choices)

# Define african and European lineages
african_lineages = ['L']
euro_lineages = ['X','X1', 'X2','I', 'W', 'R0', 'R0a', 'H', 'HV', 'V', 'JT', 'J', 'T', 'U', 'K', 'N1', 'N2']

# use user choice to filter mitomster output and exclude unwanted samples
haplo_choice = african_lineages if reply == 'African' else euro_lineages


# Identify individuals without chosen haplogroups and poor haplogroup quality scores that will be removed from the dataset
samples_removed = mitomaster_output.copy()
samples_removed = samples_removed.loc[(samples_removed['haplogroup_quality'] <= 90)|(samples_removed['haplogroup_quality'] > 100)|(~samples_removed['haplogrep_haplogroup'].str.contains('|'.join(haplo_choice))),['sample', 'haplogrep_haplogroup', 'haplogroup_quality', 'status', 'sex', 'age']]
samples_removed = samples_removed.drop_duplicates(subset='sample', keep='first')

# use easygui to allow user to select the folder where they would like to save their output files to
dir_of_analysis_files = easygui.diropenbox(msg='Please select the folder in which to save your analysis output files',
                                           title='Select a folder')
# change the directory to the one selected by the user
os.chdir(dir_of_analysis_files)

# make a txt file with info of samples removed
samples_removed.to_csv('samples_excluded_from_analysis.txt', sep='\t', index=False)

# Filter mitomaster output for samples with haplogroup quality >90 and a haplogroup == to the lineage selected by the user
mitomaster_output = mitomaster_output.loc[((mitomaster_output['haplogroup_quality'] > 90) & (mitomaster_output['haplogroup_quality'] <= 100)) &
                                      (mitomaster_output['haplogrep_haplogroup'].str.contains('|'.join(haplo_choice)))]
# replace nan values with 0
mitomaster_output.loc[:,'other'] = mitomaster_output.loc[:,'other'].fillna('missing')

# save raw mitomaster file
mitomaster_output.to_excel('mitomaster_output.xlsx', index=False)

print('Importing all your selected files...')

# SAMPLE INFO
# -----------
samples_in_analysis = mitomaster_output.drop_duplicates(subset='sample', keep='first')
# count the total number of cases
count_cases_in_analysis = (samples_in_analysis['status'] == 'case').sum()
# count the total number of controls
count_controls_in_analysis = (samples_in_analysis['status'] == 'control').sum()

# make a list of samples included in the analysis with duplicates removed

sample_list = samples_in_analysis['sample'].tolist()
sample_list = list(dict.fromkeys(sample_list))

# HAPLOGROUP ANALYSIS
# -------------------

# Find the count of cases and controls from each haplogroup
haplogroups = mitomaster_output.drop_duplicates(subset='sample', keep='first')
##TODO add haplogroups to sample info?
# make a copy of df and add column with simple haplogroups
haplogroups = haplogroups.copy()
haplogroups.loc[:, 'simple_haplogroup'] = haplogroups.haplogrep_haplogroup.str[:2]

# add haplogroups to sample_info df
sample_info_with_haplogroups = haplogroups[['sample', 'haplogrep_haplogroup']]
sample_info_with_haplogroups = sample_info_with_haplogroups.merge(sample_info, on='sample')
# save df for SPSS/excel input
output_haplogroups = haplogroups[['sample', 'status', 'haplogrep_haplogroup', 'simple_haplogroup']]

# count individuals in each simple haplogroup
simple_haplogroups_count = haplogroups.groupby(['status'])['simple_haplogroup'].value_counts().to_frame(
    'count_of_individuals').reset_index()
simple_haplogroups_count = percentage(simple_haplogroups_count, 'count_of_individuals')
# convert simple_haplogroup col to str
simple_haplogroups_count = simple_haplogroups_count.astype({'simple_haplogroup': str, 'percentage': float})

# count individuals in each (mitomaster) haplogroup
haplogroups_count = haplogroups.groupby(['status'])['mitomaster_haplogroup'].value_counts().to_frame(
    'count_of_individuals').reset_index()
haplogroups_count = percentage(haplogroups_count, 'count_of_individuals')
# convert mitomaster_haplogroup col to str
haplogroups_count = haplogroups_count.astype({'mitomaster_haplogroup': str, 'percentage': float})

# count individuals in each (haplogrep 2) haplogroup
haplogrep_haplogroups_count = haplogroups.groupby(['status'])['haplogrep_haplogroup'].value_counts().to_frame(
    'count_of_individuals').reset_index()
haplogrep_haplogroups_count = percentage(haplogrep_haplogroups_count, 'count_of_individuals')
# convert mitomaster_haplogroup col to str
haplogrep_haplogroups_count = haplogrep_haplogroups_count.astype({'haplogrep_haplogroup': str, 'percentage': float})


# WHOLE GENOME
# ------------
# make a copy of the dataframe for whole genome variants
mtDNA_var = mitomaster_output.copy()

# COMMON OUT OF PLACE VARIANTS
# ---------------

# make a new df with common out of place variants (i.e. local private Pylotree variants)
common_mtDNA_var = rare_variants_df(mtDNA_var, 'common_var', sample_list, sample_info_with_haplogroups)

# calculate count of variants per person
common_mtDNA_var_count = variant_count(common_mtDNA_var, mtDNA_region='mtDNA')

# make df's for fisher's exact test and to make a graph
common_mtDNA_var_cross_tab, common_mtDNA_var_cross_tab_graph = fishers_exact_df_and_graph_df \
    (common_mtDNA_var, 'sample_has_common_mtDNA_var', 'mtDNA')


print('Analysing rRNA variants...')

# rRNA VARIANTS
# -------------

# Filter for rRNA variants

# make a copy of the df for rRNA variants
rRNA_var = mitomaster_output.copy()
# make a new column
rRNA_var.loc[rRNA_var['other'].str.contains('rRNA'), 'rRNA'] = rRNA_var['other']
# drop all rows without rRNA variants
rRNA_var = rRNA_var.dropna(subset=['rRNA'])

# COMMON OUT OF PLACE VARIANTS

# make a new df with common out of place rRNA variants
common_rRNA_var = rare_variants_df(rRNA_var, 'common_var', sample_list, sample_info)
# calculate count of variants per person
common_rRNA_var_count = variant_count(common_rRNA_var, mtDNA_region='rRNA')

# make df's for fisher's exact test and to make a graph
common_rRNA_var_cross_tab, common_rRNA_var_cross_tab_graph = fishers_exact_df_and_graph_df \
    (common_rRNA_var, 'sample_has_common_rRNA_var', 'rRNA')


# tRNA VARIANTS
# -------------
print('Analysing tRNA variants...')

# Filter for tRNA variants

# make a copy of the dataframe for tRNA variants
tRNA_var = mitomaster_output.copy()
# make a new column
tRNA_var.loc[tRNA_var['other'].str.contains('MitoTIP'), 'mitotip_score'] = tRNA_var["other"]
# drop all rows that aren't tRNA variants
tRNA_var = tRNA_var.dropna(subset=['mitotip_score'])
# extract mitotip score from column
tRNA_var['mitotip_score'] = tRNA_var['mitotip_score'].str.extract('(\d+\.\d+)', expand=True)
# convert column to float
tRNA_var = tRNA_var.astype({'mitotip_score': float})

# add samples to df without mitotip score
tRNA_var_appended = appended_df(tRNA_var, sample_list, sample_info)
tRNA_var_appended.to_excel('tRNA.xls', index=False, sheet_name='tRNA')

# COMMON OUT OF PLACE VARIANTS

# make a new df with common out of place tRNA variants
common_tRNA_var = rare_variants_df(tRNA_var, 'common_var', sample_list, sample_info)
# calculate count of variants per person
common_tRNA_var_count = variant_count(common_tRNA_var, mtDNA_region='tRNA')
# make df's for fisher's exact test and to make a graph
common_tRNA_var_cross_tab, common_tRNA_var_cross_tab_graph = fishers_exact_df_and_graph_df \
    (common_tRNA_var, 'sample_has_common_tRNA_var', 'tRNA')


# NON-CODING VARIANTS
# ------------------

print('Analysing non-coding variants...')
# Filter for non-coding variants

# make a copy of the df for non-coding variants
noncoding_var = mitomaster_output.copy()
# make a new column
noncoding_var.loc[noncoding_var['other'].str.contains('non-coding'), 'non_coding'] = noncoding_var['other']
# drop all rows without noncoding variants
noncoding_var = noncoding_var.dropna(subset=['non_coding'])

# COMMON OUT OF PLACE VARIANTS

# make a new df with common out-of-place noncoding variants
common_noncoding_var = rare_variants_df(noncoding_var, 'common_var', sample_list, sample_info)
# calculate count of variants per person
common_noncoding_var_count = variant_count(common_noncoding_var, mtDNA_region='noncoding')
# make df's for fisher's exact test and to make a graph
common_noncoding_var_cross_tab, common_noncoding_var_cross_tab_graph = fishers_exact_df_and_graph_df \
    (common_noncoding_var, 'sample_has_common_noncoding_var', 'noncoding')




# # TODO Idea: make a for loop to df's for different loci and apply the same functions to all instead of repeating
#  the code each time

# ALL CODING VARIANTS
# -------------------

print('Analysing coding variants...')

# Filter for coding variants

# make a copy of the df for coding variants
coding_var = mitomaster_output.copy()
coding_var.loc[coding_var['other'].str.contains(':'), 'coding'] = coding_var['other']
coding_var = coding_var.dropna(subset=['coding'])
# drop all rows without coding variants
coding_var[['coding', 'mitomaster_AAC']] = coding_var.coding.str.split(':', 1, expand=True)
# assign OXPHOS gene complexes based on locus
coding_var['oxphos_complex'] = pd.np.where(
    coding_var.locus.str.contains('ND'), 'CI',
    pd.np.where(coding_var.locus.str.contains('Cytb'), 'CIII',
                pd.np.where(coding_var.locus.str.contains('COI'), 'CIV',
                            pd.np.where(coding_var.locus.str.contains('ATP'), 'CV', 'NaN'))))

# COMMON OUT OF PLACE VARIANTS

# make a new df with common out of place coding variants
common_coding_var = rare_variants_df(coding_var, 'common_var', sample_list, sample_info)
# calculate count of variants per person
common_coding_var_count = variant_count(common_coding_var, mtDNA_region='coding')
# make df's for fisher's exact test and to make a graph
common_coding_var_cross_tab, common_coding_var_cross_tab_graph = fishers_exact_df_and_graph_df \
    (common_coding_var, 'sample_has_common_coding_var', 'coding')




## TODO # calculate count of variants per person for oxphos variants

# ALL CODING OXPHOS VARIANTS
# ------------------------------

# Filter for all coding OXPHOS variants

# make a copy of the df
coding_oxphos_var = coding_var.copy()

# filter for coding_CI

coding_CI_filter = coding_oxphos_var['oxphos_complex'] == 'CI'
coding_CI_var = coding_oxphos_var[coding_CI_filter]

# COMMON OUT OF PLACE VARIANTS

# make a new df with common out-of-place coding_CI variants
common_coding_CI_var = rare_variants_df(coding_CI_var, 'common_var', sample_list, sample_info)
# calculate count of variants per person
common_coding_CI_var_count = variant_count(common_coding_CI_var, mtDNA_region='coding_CI')
# make df's for fisher's exact test and to make a graph
common_coding_CI_var_cross_tab, common_coding_CI_var_cross_tab_graph = fishers_exact_df_and_graph_df \
    (common_coding_CI_var, 'sample_has_common_coding_CI_var', 'coding_CI')


# filter for coding_CIII

coding_CIII_filter = coding_oxphos_var['oxphos_complex'] == 'CIII'
coding_CIII_var = coding_oxphos_var[coding_CIII_filter]

# COMMON OUT OF PLACE VARIANTS

# make a new df with rare haplogroup coding_CIII variants
common_coding_CIII_var = rare_variants_df(coding_CIII_var, 'common_var', sample_list, sample_info)
# calculate count of variants per person
common_coding_CIII_var_count = variant_count(common_coding_CIII_var, mtDNA_region='coding_CIII')
# make df's for fisher's exact test and to make a graph
common_coding_CIII_var_cross_tab, common_coding_CIII_var_cross_tab_graph = fishers_exact_df_and_graph_df \
    (common_coding_CIII_var, 'sample_has_common_coding_CIII_var', 'coding_CIII')


# filter for coding_CIV

coding_CIV_filter = coding_oxphos_var['oxphos_complex'] == 'CIV'
coding_CIV_var = coding_oxphos_var[coding_CIV_filter]

# COMMON OUT OF PLACE VARIANTS

# make a new df with rare haplogroup coding_CIV variants
common_coding_CIV_var = rare_variants_df(coding_CIV_var, 'common_var', sample_list, sample_info)
# calculate count of variants per person
common_coding_CIV_var_count = variant_count(common_coding_CIV_var, mtDNA_region='coding_CIV')
# make df's for fisher's exact test and to make a graph
common_coding_CIV_var_cross_tab, common_coding_CIV_var_cross_tab_graph = fishers_exact_df_and_graph_df \
    (common_coding_CIV_var, 'sample_has_common_coding_CIV_var', 'coding_CIV')


# filter for coding_CV

coding_CV_filter = coding_oxphos_var['oxphos_complex'] == 'CV'
coding_CV_var = coding_oxphos_var[coding_CV_filter]

# COMMON OUT OF PLACE VARIANTS

# make a new df with rare haplogroup coding_CV variants
common_coding_CV_var = rare_variants_df(coding_CV_var, 'common_var', sample_list, sample_info)
# calculate count of variants per person
common_coding_CV_var_count = variant_count(common_coding_CV_var, mtDNA_region='coding_CV')
# make df's for fisher's exact test and to make a graph
common_coding_CV_var_cross_tab, common_coding_CV_var_cross_tab_graph = fishers_exact_df_and_graph_df \
    (common_coding_CV_var, 'sample_has_common_coding_CV_var', 'coding_CV')



# SYNONYMOUS VARIANTS
# -------------------

# Filter for synonymous variants

# make a copy of the df for synonymous variants
syn_var = coding_var.copy()

# drop all rows which have an AAC and make a new col for synonymous variants
syn_var = syn_var[pd.isnull(syn_var['AAC'])]
syn_var.loc[:, 'synonymous'] = 'syn_var'

# COMMON OUT OF PLACE VARIANTS

# make a new df with rare haplogroup syn variants
common_syn_var = rare_variants_df(syn_var, 'common_var', sample_list, sample_info)
# calculate count of variants per person
common_syn_var_count = variant_count(common_syn_var, mtDNA_region='syn')
# make df's for fisher's exact test and to make a graph
common_syn_var_cross_tab, common_syn_var_cross_tab_graph = fishers_exact_df_and_graph_df \
    (common_syn_var, 'sample_has_common_syn_var', 'syn')


# SYNONYMOUS OXPHOS VARIANTS
# ------------------------------

# Filter for synonymous OXPHOS variants

# make a copy of the df
syn_oxphos_var = syn_var.copy()

# filter for syn_CI

syn_CI_filter = syn_oxphos_var['oxphos_complex'] == 'CI'
syn_CI_var = syn_oxphos_var[syn_CI_filter]

# COMMON OUT OF PLACE VARIANTS

# make a new df with rare haplogroup syn_CI variants
common_syn_CI_var = rare_variants_df(syn_CI_var, 'common_var', sample_list, sample_info)
# calculate count of variants per person
common_syn_CI_var_count = variant_count(common_syn_CI_var, mtDNA_region='syn_CI')
# make df's for fisher's exact test and to make a graph
common_syn_CI_var_cross_tab, common_syn_CI_var_cross_tab_graph = fishers_exact_df_and_graph_df \
    (common_syn_CI_var, 'sample_has_common_syn_CI_var', 'syn_CI')


# filter for syn_CIII

syn_CIII_filter = syn_oxphos_var['oxphos_complex'] == 'CIII'
syn_CIII_var = syn_oxphos_var[syn_CIII_filter]

# COMMON OUT OF PLACE VARIANTS

# make a new df with rare haplogroup syn_CIII variants
common_syn_CIII_var = rare_variants_df(syn_CIII_var, 'common_var', sample_list, sample_info)
# calculate count of variants per person
common_syn_CIII_var_count = variant_count(common_syn_CIII_var, mtDNA_region='syn_CIII')
# make df's for fisher's exact test and to make a graph
common_syn_CIII_var_cross_tab, common_syn_CIII_var_cross_tab_graph = fishers_exact_df_and_graph_df \
    (common_syn_CIII_var, 'sample_has_common_syn_CIII_var', 'syn_CIII')



# filter for syn_CIV

syn_CIV_filter = syn_oxphos_var['oxphos_complex'] == 'CIV'
syn_CIV_var = syn_oxphos_var[syn_CIV_filter]

# COMMON OUT OF PLACE VARIANTS

# make a new df with rare haplogroup syn_CIV variants
common_syn_CIV_var = rare_variants_df(syn_CIV_var, 'common_var', sample_list, sample_info)
# calculate count of variants per person
common_syn_CIV_var_count = variant_count(common_syn_CIV_var, mtDNA_region='syn_CIV')
# make df's for fisher's exact test and to make a graph
common_syn_CIV_var_cross_tab, common_syn_CIV_var_cross_tab_graph = fishers_exact_df_and_graph_df \
    (common_syn_CIV_var, 'sample_has_common_syn_CIV_var', 'syn_CIV')



# filter for syn_CV

syn_CV_filter = syn_oxphos_var['oxphos_complex'] == 'CV'
syn_CV_var = syn_oxphos_var[syn_CV_filter]

# COMMON OUT OF PLACE VARIANTS

# make a new df with rare haplogroup syn_CV variants
common_syn_CV_var = rare_variants_df(syn_CV_var, 'common_var', sample_list, sample_info)
# calculate count of variants per person
common_syn_CV_var_count = variant_count(common_syn_CV_var, mtDNA_region='syn_CV')
# make df's for fisher's exact test and to make a graph
common_syn_CV_var_cross_tab, common_syn_CV_var_cross_tab_graph = fishers_exact_df_and_graph_df \
    (common_syn_CV_var, 'sample_has_common_syn_CV_var', 'syn_CV')



# NON-SYNONYMOUS VARIANTS
# -------------------

# Filter for non-synonymous variants

# make a copy of the df
nonsyn_var = coding_var.copy()

# drop all rows which don't have AAC and make a new col for non_synonymous variants
nonsyn_var = nonsyn_var.dropna(subset=['AAC'])
nonsyn_var.loc[:, 'non_synonymous'] = 'nonsyn_var'

## TODO add samples that dont have non-synon variants


nonsyn_var_appended = appended_df(nonsyn_var, sample_list, sample_info)
nonsyn_var_appended.to_excel('nonsyn_var_appended.xls', index = False)

# COMMON OUT OF PLACE VARIANTS

# make a new df with rare haplogroup nonsyn variants
common_nonsyn_var = rare_variants_df(nonsyn_var, 'common_var', sample_list, sample_info)
# calculate count of variants per person
common_nonsyn_var_count = variant_count(common_nonsyn_var, mtDNA_region='nonsyn')
# make df's for fisher's exact test and to make a graph
common_nonsyn_var_cross_tab, common_nonsyn_var_cross_tab_graph = fishers_exact_df_and_graph_df \
    (common_nonsyn_var, 'sample_has_common_nonsyn_var', 'nonsyn')



# NON-SYNONYMOUS OXPHOS VARIANTS
# ------------------------------

print('Assigning pathogenicity scores to detected variants...')

# Filter for non-synonymous OXPHOS variants

# make a copy of the df
nonsyn_oxphos_var = nonsyn_var.copy()

# filter for nonsyn_CI

nonsyn_CI_filter = nonsyn_oxphos_var['oxphos_complex'] == 'CI'
nonsyn_CI_var = nonsyn_oxphos_var[nonsyn_CI_filter]

# COMMON OUT OF PLACE VARIANTS

# make a new df with common out-of-place nonsyn_CI variants
common_nonsyn_CI_var = rare_variants_df(nonsyn_CI_var, 'common_var', sample_list, sample_info)
# calculate count of variants per person
common_nonsyn_CI_var_count = variant_count(common_nonsyn_CI_var, mtDNA_region='nonsyn_CI')
# make df's for fisher's exact test and to make a graph
common_nonsyn_CI_var_cross_tab, common_nonsyn_CI_var_cross_tab_graph = fishers_exact_df_and_graph_df \
    (common_nonsyn_CI_var, 'sample_has_common_nonsyn_CI_var', 'nonsyn_CI')



# filter for nonsyn_CIII

nonsyn_CIII_filter = nonsyn_oxphos_var['oxphos_complex'] == 'CIII'
nonsyn_CIII_var = nonsyn_oxphos_var[nonsyn_CIII_filter]

# COMMON OUT OF PLACE VARIANTS

# make a new df with common out-of-place nonsyn_CIII variants
common_nonsyn_CIII_var = rare_variants_df(nonsyn_CIII_var, 'common_var', sample_list, sample_info)
# calculate count of variants per person
common_nonsyn_CIII_var_count = variant_count(common_nonsyn_CIII_var, mtDNA_region='nonsyn_CIII')
# make df's for fisher's exact test and to make a graph
common_nonsyn_CIII_var_cross_tab, common_nonsyn_CIII_var_cross_tab_graph = fishers_exact_df_and_graph_df \
    (common_nonsyn_CIII_var, 'sample_has_common_nonsyn_CIII_var', 'nonsyn_CIII')



# filter for nonsyn_CIV

nonsyn_CIV_filter = nonsyn_oxphos_var['oxphos_complex'] == 'CIV'
nonsyn_CIV_var = nonsyn_oxphos_var[nonsyn_CIV_filter]

# COMMON OUT OF PLACE VARIANTS

# make a new df with common out-of-place nonsyn_CIV variants
common_nonsyn_CIV_var = rare_variants_df(nonsyn_CIV_var, 'common_var', sample_list, sample_info)
# calculate count of variants per person
common_nonsyn_CIV_var_count = variant_count(common_nonsyn_CIV_var, mtDNA_region='nonsyn_CIV')
# make df's for fisher's exact test and to make a graph
common_nonsyn_CIV_var_cross_tab, common_nonsyn_CIV_var_cross_tab_graph = fishers_exact_df_and_graph_df \
    (common_nonsyn_CIV_var, 'sample_has_common_nonsyn_CIV_var', 'nonsyn_CIV')



# filter for nonsyn_CV

nonsyn_CV_filter = nonsyn_oxphos_var['oxphos_complex'] == 'CV'
nonsyn_CV_var = nonsyn_oxphos_var[nonsyn_CV_filter]

# COMMON OUT OF PLACE VARIANTS

# make a new df with common out-of-place nonsyn_CV variants
common_nonsyn_CV_var = rare_variants_df(nonsyn_CV_var, 'common_var', sample_list, sample_info)
# calculate count of variants per person
common_nonsyn_CV_var_count = variant_count(common_nonsyn_CV_var, mtDNA_region='nonsyn_CV')
# make df's for fisher's exact test and to make a graph
common_nonsyn_CV_var_cross_tab, common_nonsyn_CV_var_cross_tab_graph = fishers_exact_df_and_graph_df \
    (common_nonsyn_CV_var, 'sample_has_common_nonsyn_CV_var', 'nonsyn_CV')

# SCORED COMMON OUT-OF-PLACE NON-SYNONYMOUS VARIANTS
# --------------------------------------------------

# make a copy of the dataframe for out-of-place whole genome variants
common_scored_var = common_mtDNA_var.copy()

# Scored common-out-of-place variants

# make a new df with common out of place variants that have been scored with one of the three in silico tools as mildy deletrious
common_scored_var = rare_variants_df(common_scored_var, 'scored_variant', sample_list, sample_info_with_haplogroups)

# calculate count of variants per person
common_scored_var_count = variant_count(common_scored_var, mtDNA_region='scored_var')

# make df's for fisher's exact test and to make a graph
common_scored_var_cross_tab, common_scored_var_cross_tab_graph = fishers_exact_df_and_graph_df \
    (common_scored_var, 'sample_has_common_scored_var', 'scored_var')

# Filter for non-synonymous OXPHOS variants

# make a copy of the df
nonsyn_oxphos_var = nonsyn_var.copy()

# make a new df with common out of place variants that have been scored with one of the three in silico tools as mildy deletrious
common_scored_nonsyn_oxphos_var = rare_variants_df(nonsyn_oxphos_var, 'scored_variant', sample_list, sample_info_with_haplogroups)

# filter for nonsyn_CI

nonsyn_CI_filter = common_scored_nonsyn_oxphos_var['oxphos_complex'] == 'CI'
nonsyn_CI_var = common_scored_nonsyn_oxphos_var[nonsyn_CI_filter]

# COMMON OUT OF PLACE VARIANTS

# make a new df with common out-of-place nonsyn_CI variants
scored_common_nonsyn_CI_var = rare_variants_df(nonsyn_CI_var, 'common_var', sample_list, sample_info)
# calculate count of variants per person
scored_common_nonsyn_CI_var_count = variant_count(scored_common_nonsyn_CI_var, mtDNA_region='nonsyn_CI')
# make df's for fisher's exact test and to make a graph
scored_common_nonsyn_CI_var_cross_tab, scored_common_nonsyn_CI_var_cross_tab_graph = fishers_exact_df_and_graph_df \
    (scored_common_nonsyn_CI_var, 'sample_has_scored_common_nonsyn_CI_var', 'nonsyn_CI')



# filter for nonsyn_CIII

nonsyn_CIII_filter = common_scored_nonsyn_oxphos_var['oxphos_complex'] == 'CIII'
nonsyn_CIII_var = common_scored_nonsyn_oxphos_var[nonsyn_CIII_filter]

# COMMON OUT OF PLACE VARIANTS

# make a new df with common out-of-place nonsyn_CIII variants
scored_common_nonsyn_CIII_var = rare_variants_df(nonsyn_CIII_var, 'common_var', sample_list, sample_info)
# calculate count of variants per person
scored_common_nonsyn_CIII_var_count = variant_count(scored_common_nonsyn_CIII_var, mtDNA_region='nonsyn_CIII')
# make df's for fisher's exact test and to make a graph
scored_common_nonsyn_CIII_var_cross_tab, scored_common_nonsyn_CIII_var_cross_tab_graph = fishers_exact_df_and_graph_df \
    (scored_common_nonsyn_CIII_var, 'sample_has_scored_common_nonsyn_CIII_var', 'nonsyn_CIII')



# filter for nonsyn_CIV

nonsyn_CIV_filter = common_scored_nonsyn_oxphos_var['oxphos_complex'] == 'CIV'
nonsyn_CIV_var = common_scored_nonsyn_oxphos_var[nonsyn_CIV_filter]

# COMMON OUT OF PLACE VARIANTS

# make a new df with common out-of-place nonsyn_CIV variants
scored_common_nonsyn_CIV_var = rare_variants_df(nonsyn_CIV_var, 'common_var', sample_list, sample_info)
# calculate count of variants per person
scored_common_nonsyn_CIV_var_count = variant_count(scored_common_nonsyn_CIV_var, mtDNA_region='nonsyn_CIV')
# make df's for fisher's exact test and to make a graph
scored_common_nonsyn_CIV_var_cross_tab, scored_common_nonsyn_CIV_var_cross_tab_graph = fishers_exact_df_and_graph_df \
    (scored_common_nonsyn_CIV_var, 'sample_has_scored_common_nonsyn_CIV_var', 'nonsyn_CIV')


# filter for nonsyn_CV

nonsyn_CV_filter = common_scored_nonsyn_oxphos_var['oxphos_complex'] == 'CV'
nonsyn_CV_var = common_scored_nonsyn_oxphos_var[nonsyn_CV_filter]

# COMMON OUT OF PLACE VARIANTS

# make a new df with common out-of-place nonsyn_CV variants
scored_common_nonsyn_CV_var = rare_variants_df(nonsyn_CV_var, 'common_var', sample_list, sample_info)
# calculate count of variants per person
scored_common_nonsyn_CV_var_count = variant_count(scored_common_nonsyn_CV_var, mtDNA_region='nonsyn_CV')
# make df's for fisher's exact test and to make a graph
scored_common_nonsyn_CV_var_cross_tab, scored_common_nonsyn_CV_var_cross_tab_graph = fishers_exact_df_and_graph_df \
    (scored_common_nonsyn_CV_var, 'sample_has_scored_common_nonsyn_CV_var', 'nonsyn_CV')




# GRAPHS
# ------

print('Saving your results...')

# customise seaborn graphs
sns.set_context('paper') # or talk
sns.set_style("white")
my_colors = ['magenta', 'deepskyblue', 'coral', 'crimson', 'mediumspringgreen', ]
sns.set_palette(my_colors)

# HAPLOGROUP GRAPH

# Haplogroup distribution without error bars

# create a new figure
plt.figure() # can put figsize

# plot the graph in the new figure
simple_haplogroups_count_plot = sns.barplot(x='simple_haplogroup', y='percentage', hue='status',
                                            data=simple_haplogroups_count,  edgecolor = "grey", linewidth = 1, ci=None)
simple_haplogroups_count_plot.set_xlabel('African Haplogroups', fontsize=12, weight='bold', labelpad=18)
# simple_haplogroups_count_plot.set_xticklabels(['Cases', 'Controls'])
simple_haplogroups_count_plot.set_ylabel('Percentage of individuals (%)', fontsize=12, weight='bold', labelpad=18)
simple_haplogroups_count_plot.set_title('Percentage of individuals from each haplogroup', fontsize=14,
                                        weight='bold',
                                        pad=18)
simple_haplogroups_count_plot.legend(title='Status group', loc='upper right')
simple_haplogroups_count_plot = barplot_labels(simple_haplogroups_count_plot)

# save plot as a .png file
plt.savefig('simple_haplogroups_count_plot.png', transparent=True, dpi=300, bbox_inches='tight')

# COMMON OUT OF PLACE VARIANTS GRAPH

# create a new figure
plt.figure(figsize=(10,6))
# get the data for the graph you want to plot in the figure
common_variants = pd.concat([common_mtDNA_var_cross_tab_graph, common_rRNA_var_cross_tab_graph,
                             common_tRNA_var_cross_tab_graph,
                             common_noncoding_var_cross_tab_graph, common_coding_var_cross_tab_graph],
                            ignore_index=True, sort=False)

# specify values
common_variants_plot = sns.barplot(x='rare_var', y='percentage', hue='status', data=common_variants,  edgecolor = "grey", linewidth = 1)
common_variants_plot.set_xlabel('mtDNA region', fontsize=12, weight='bold', labelpad=18)
common_variants_plot.set_xticklabels(
    ['Whole mtDNA', 'rRNA genes', 'tRNA genes', 'non-coding', 'OXPHOS genes'])
common_variants_plot.set_ylabel('Percentage of individuals (%)', fontsize=12, weight='bold', labelpad=18)
common_variants_plot.set_title('Percentage of individuals with out-of-place variants', fontsize=14,
                               weight='bold',
                               pad=18)
# place the legend outside the figure/plot
common_variants_plot.legend(title='Status group', bbox_to_anchor=(1.01, 1),
           borderaxespad=0)

common_variants_plot = barplot_labels(common_variants_plot)

# save plot as a .png file
plt.savefig('common_variants_plot.png', transparent=True, dpi=300, bbox_inches='tight')


# COMMON OUT OF PLACE NON-SYNONYMOUS VARIANTS GRAPH

# create a new figure
plt.figure()
# get the data for the graph you want to plot in the figure
common_nonsyn_variants = pd.concat([
    common_nonsyn_var_cross_tab_graph,
    common_nonsyn_CI_var_cross_tab_graph, common_nonsyn_CIII_var_cross_tab_graph,
    common_nonsyn_CIV_var_cross_tab_graph, common_nonsyn_CV_var_cross_tab_graph],
    ignore_index=True, sort=False)

common_nonsyn_variants_plot = sns.barplot(x='rare_var', y='percentage', hue='status',
                                          data=common_nonsyn_variants,  edgecolor = "grey", linewidth = 1)
common_nonsyn_variants_plot.set_xlabel('mtDNA region', fontsize=12, weight='bold', labelpad=18)
common_nonsyn_variants_plot.set_xticklabels(['All OXPHOS complexes', 'CI', 'CIII', 'CIV', 'CV'])
common_nonsyn_variants_plot.set_ylabel('Percentage of individuals (%)', fontsize=12, weight='bold',
                                       labelpad=18)
common_nonsyn_variants_plot.set_title('Percentage of individuals with non-synonymous out-of-place variants',
                                      fontsize=14, weight='bold',
                                      pad=18)
common_nonsyn_variants_plot.legend(title='Status group', loc='upper right')
common_nonsyn_variants_plot = barplot_labels(common_nonsyn_variants_plot)

# save plot as a .png file
plt.savefig('common_nonsyn_variants_plot.png', transparent=True, dpi=300, bbox_inches='tight')

# COMMON OUT OF PLACE SCORED NON-SYNONYMOUS VARIANTS GRAPH

# create a new figure
plt.figure()
# get the data for the graph you want to plot in the figure
scored_common_nonsyn_variants = pd.concat([
    common_scored_var_cross_tab_graph,
    scored_common_nonsyn_CI_var_cross_tab_graph, scored_common_nonsyn_CIII_var_cross_tab_graph,
    scored_common_nonsyn_CIV_var_cross_tab_graph, scored_common_nonsyn_CV_var_cross_tab_graph],
    ignore_index=True, sort=False)

print(scored_common_nonsyn_variants)

scored_common_nonsyn_variants_plot = sns.barplot(x='rare_var', y='percentage', hue='status',
                                          data=scored_common_nonsyn_variants,  edgecolor = "grey", linewidth = 1)
scored_common_nonsyn_variants_plot.set_xlabel('mtDNA region', fontsize=12, weight='bold', labelpad=18)
scored_common_nonsyn_variants_plot.set_xticklabels(['All OXPHOS complexes', 'CI', 'CIII', 'CIV', 'CV'])
scored_common_nonsyn_variants_plot.set_ylabel('Percentage of individuals (%)', fontsize=12, weight='bold',
                                       labelpad=18)
scored_common_nonsyn_variants_plot.set_title('Percentage of individuals with scored, non-synonymous out-of-place variants',
                                      fontsize=14, weight='bold',
                                      pad=18)
scored_common_nonsyn_variants_plot.legend(title='Status group', loc='upper right')
scored_common_nonsyn_variants_plot = barplot_labels(scored_common_nonsyn_variants_plot)

# save plot as a .png file
plt.savefig('scored_common_nonsyn_variants_plot.png', transparent=True, dpi=300, bbox_inches='tight')


# COMMON OUT OF PLACE SYNONYMOUS VARIANTS GRAPH

# create a new figure
plt.figure()
# get the data for the graph you want to plot in the figure
common_syn_variants = pd.concat([
    common_syn_var_cross_tab_graph,
    common_syn_CI_var_cross_tab_graph, common_syn_CIII_var_cross_tab_graph,
    common_syn_CIV_var_cross_tab_graph, common_syn_CV_var_cross_tab_graph],
    ignore_index=True, sort=False)

common_syn_variants_plot = sns.barplot(x='rare_var', y='percentage', hue='status',
                                          data=common_syn_variants,  edgecolor = "grey", linewidth = 1)
common_syn_variants_plot.set_xlabel('mtDNA region', fontsize=12, weight='bold', labelpad=18)
common_syn_variants_plot.set_xticklabels(['All OXPHOS complexes', 'CI', 'CIII', 'CIV', 'CV'])
common_syn_variants_plot.set_ylabel('Percentage of individuals (%)', fontsize=12, weight='bold',
                                       labelpad=18)
common_syn_variants_plot.set_title('Percentage of individuals with synonymous out-of-place variants',
                                      fontsize=14, weight='bold',
                                      pad=18)
common_syn_variants_plot.legend(title='Status group', loc='upper right')
common_syn_variants_plot = barplot_labels(common_syn_variants_plot)

# save plot as a .png file
plt.savefig('common_syn_variants_plot.png', transparent=True, dpi=300, bbox_inches='tight')

# COUNT COMMON OUT-OF-PLACE NON-SYNONYMOUS VARIANTS COUNTS GRAPH

# create a new figure
plt.figure()
# get the data for the graph you want to plot in the figure
common_nonsyn_var_counts = pd.concat([
    common_nonsyn_var_count, common_nonsyn_CI_var_count, common_nonsyn_CIII_var_count,
    common_nonsyn_CIV_var_count, common_nonsyn_CV_var_count],
    ignore_index=True, sort=False)

common_nonsyn_var_counts_plot = sns.barplot(x='status', y='percentage', hue='variant_count',
                                             data=common_nonsyn_var_count,  edgecolor = "grey", linewidth = 1)
common_nonsyn_var_counts_plot.set_xlabel('Status group', fontsize=12, weight='bold', labelpad=18)
# common_nonsyn_var_counts_plot.set_xticklabels([])
common_nonsyn_var_counts_plot.set_ylabel('Percentage of individuals (%)', fontsize=12, weight='bold', labelpad=18)
common_nonsyn_var_counts_plot.set_title('Percentage of individuals with out-of-place nonsynonymous variants',
                                         fontsize=14, weight='bold',
                                         pad=18)
common_nonsyn_var_counts_plot.legend(title='variant_count', loc='upper right')
common_nonsyn_var_counts_plot = barplot_labels(common_nonsyn_var_counts_plot)

# save plot as a .png file
plt.savefig('common_nonsyn_var_counts_plot.png', transparent=True, dpi=300, bbox_inches='tight')


# COUNT COMMON OUT-OF-PLACE SYNONYMOUS VARIANTS COUNTS GRAPH

# create a new figure
plt.figure()
# get the data for the graph you want to plot in the figure
common_syn_var_counts = pd.concat([
    common_syn_var_count, common_syn_CI_var_count, common_syn_CIII_var_count,
    common_syn_CIV_var_count, common_syn_CV_var_count],
    ignore_index=True, sort=False)

common_syn_var_counts_plot = sns.barplot(x='status', y='percentage', hue='variant_count',
                                             data=common_syn_var_count,  edgecolor = "grey", linewidth = 1)
common_syn_var_counts_plot.set_xlabel('Status group', fontsize=12, weight='bold', labelpad=18)
# common_syn_var_counts_plot.set_xticklabels([])
common_syn_var_counts_plot.set_ylabel('Percentage of individuals (%)', fontsize=12, weight='bold', labelpad=18)
common_syn_var_counts_plot.set_title('Percentage of individuals with out-of-place synonymous variants',
                                         fontsize=14, weight='bold',
                                         pad=18)
common_syn_var_counts_plot.legend(title='variant_count', loc='upper right')
common_syn_var_counts_plot = barplot_labels(common_syn_var_counts_plot)

# save plot as a .png file
plt.savefig('common_syn_var_counts_plot.png', transparent=True, dpi=300, bbox_inches='tight')


# MUTPRED VARIANT ANALYSIS (SCORE >0.5)


# ALL NON-SYNONYMOUS VARIANTS

# todo ask user to define MutPred cut-off

# Calculate variant load per person and mutpred-scored variant count per person for all non-synonymous variants
nonsyn_var_mutpred_variant_load, nonsyn_var_mutpred_count = pathogenic_scoring(dataframe=nonsyn_var_appended,
                                                                               pathogenic_cutoff_value=0.5,
                                                                               pathogenic_col_name='MutPred')


# Find the number of individuals from each status group who have mutpred-scored variants
nonsyn_var_mutpred_count_grouped = variant_counts_grouped_by_counts(nonsyn_var_mutpred_count, 'pathogenic_count')

# make swarmplot for variant loads

# create a new figure
plt.figure()

mutpred_variant_load_plot = sns.swarmplot(x='status', y='variant_load', data=nonsyn_var_mutpred_variant_load)
mutpred_variant_load_plot.set_xlabel('Status group', fontsize=12, weight='bold', labelpad=18)
mutpred_variant_load_plot.set_xticklabels(['Cases', 'Controls'])
mutpred_variant_load_plot.set_ylabel('MutPred variant load', fontsize=12, weight='bold', labelpad=18)
mutpred_variant_load_plot.set_title('MutPred variant loads per person',
                                    fontsize=14, weight='bold',
                                    pad=18)

# save plot as a .png file
plt.savefig('mutpred_variant_load_plot.png', transparent=True, dpi=300, bbox_inches='tight')

# GRAPH: ALL NON-SYNONYMOUS MUTPRED-SCORED VARIANTS >0.5

# create a new figure
plt.figure()

nonsyn_var_mutpred_count_grouped_plot = sns.barplot(x='pathogenic_count', y='percentage', hue='status',
                                                    data=nonsyn_var_mutpred_count_grouped)
nonsyn_var_mutpred_count_grouped_plot.set_xlabel('Count of MutPred-scored variants', fontsize=12, weight='bold',
                                                 labelpad=18)
# nonsyn_var_mutpred_count_grouped_plot.set_xticklabels(['Whole mtDNA', 'rRNA genes', 'tRNA genes', 'MDPs', 'non-cdoing', 'OXPHOS genes'])
nonsyn_var_mutpred_count_grouped_plot.set_ylabel('Percentage of individuals (%)', fontsize=12, weight='bold',
                                                 labelpad=18)
nonsyn_var_mutpred_count_grouped_plot.set_title('Percentage of individuals with MutPred-scored variants >0.5',
                                                fontsize=14, weight='bold',
                                                pad=18)
nonsyn_var_mutpred_count_grouped_plot.legend(title='Status group', loc='upper right')
nonsyn_var_mutpred_count_grouped_plot = barplot_labels(nonsyn_var_mutpred_count_grouped_plot)

# save plot as a .png file
plt.savefig('nonsyn_var_mutpred_count_grouped_plot.png', transparent=True, dpi=300, bbox_inches='tight')


# COMMON OUT-OF-PLACE NON-SYNONYMOUS VARIANTS

# Calculate variant load per person and mutpred-scored variant count per person for out-of-place non-synonymous  variants
common_nonsyn_var_mutpred_variant_load, common_nonsyn_var_mutpred_count = \
    pathogenic_scoring(dataframe=common_nonsyn_var, pathogenic_cutoff_value=0.5, pathogenic_col_name='MutPred')
# Find the number of individuals from each status group who have rare haplo mutpred-scored variants grouped by count
common_nonsyn_var_mutpred_count_grouped = variant_counts_grouped_by_counts(common_nonsyn_var_mutpred_count,
                                                                               'pathogenic_count')



# MtoolBox VARIANT ANALYSIS (SCORE >0.4311)


# ALL NON-SYNONYMOUS VARIANTS

# Calculate variant load per person and mtoolbox-scored variant count per person for all non-synonymous variants
nonsyn_var_mtoolbox_variant_load, nonsyn_var_mtoolbox_count = pathogenic_scoring(dataframe=nonsyn_var_appended,
                                                                                 pathogenic_cutoff_value=0.4311,
                                                                                 pathogenic_col_name='mtoolbox_ds')
# Find the number of individuals from each status group who have mtoolbox-scored variants
nonsyn_var_mtoolbox_count_grouped = variant_counts_grouped_by_counts(nonsyn_var_mtoolbox_count, 'pathogenic_count')

# make swarmplot for variant loads

# create a new figure
plt.figure()

mtoolbox_variant_load_plot = sns.swarmplot(x='status', y='variant_load', data=nonsyn_var_mtoolbox_variant_load)
mtoolbox_variant_load_plot.set_xlabel('Status group', fontsize=12, weight='bold', labelpad=18)
mtoolbox_variant_load_plot.set_xticklabels(['Cases', 'Controls'])
mtoolbox_variant_load_plot.set_ylabel('MToolbox variant load', fontsize=12, weight='bold', labelpad=18)
mtoolbox_variant_load_plot.set_title('MToolbox variant loads per person',
                                     fontsize=14, weight='bold',
                                     pad=18)

# save plot as a .png file
plt.savefig('mtoolbox_variant_load_plot.png', transparent=True, dpi=300, bbox_inches='tight')

# GRAPH: ALL NON-SYNONYMOUS mtoolbox-SCORED VARIANTS >0.4311

# create a new figure
plt.figure()

nonsyn_var_mtoolbox_count_grouped_plot = sns.barplot(x='pathogenic_count', y='percentage', hue='status',
                                                     data=nonsyn_var_mtoolbox_count_grouped)
nonsyn_var_mtoolbox_count_grouped_plot.set_xlabel('Count of MToolbox-scored variants', fontsize=12, weight='bold',
                                                  labelpad=18)
# nonsyn_var_mtoolbox_count_grouped_plot.set_xticklabels(['Whole mtDNA', 'rRNA genes', 'tRNA genes', 'MDPs', 'non-cdoing', 'OXPHOS genes'])
nonsyn_var_mtoolbox_count_grouped_plot.set_ylabel('Percentage of individuals (%)', fontsize=12, weight='bold',
                                                  labelpad=18)
nonsyn_var_mtoolbox_count_grouped_plot.set_title('Percentage of individuals with MToolbox-scored variants >0.4311',
                                                 fontsize=14, weight='bold',
                                                 pad=18)
nonsyn_var_mtoolbox_count_grouped_plot.legend(title='Status group', loc='upper right')
nonsyn_var_mtoolbox_count_grouped_plot = barplot_labels(nonsyn_var_mtoolbox_count_grouped_plot)

# save plot as a .png file
plt.savefig('nonsyn_var_mtoolbox_count_grouped_plot.png', transparent=True, dpi=300, bbox_inches='tight')

# save variant load df to SPSS file
pyreadstat.write_sav(nonsyn_var_mtoolbox_variant_load, dir_of_analysis_files)

# COMMON OUT-OF-PLACE NON-SYNONYMOUS VARIANTS

# Calculate variant load per person and mtoolbox-scored variant count per person for out-of-place non-synonymous  variants
common_nonsyn_var_mtoolbox_variant_load, common_nonsyn_var_mtoolbox_count = \
    pathogenic_scoring(dataframe=common_nonsyn_var, pathogenic_cutoff_value=0.4311,
                       pathogenic_col_name='mtoolbox_ds')
# Find the number of individuals from each status group who have rare haplo mtoolbox-scored variants grouped by count
common_nonsyn_var_mtoolbox_count_grouped = variant_counts_grouped_by_counts(common_nonsyn_var_mtoolbox_count,
                                                                                'pathogenic_count')

# APOGEE VARIANT ANALYSIS (SCORE >0.5)

# ALL NON-SYNONYMOUS VARIANTS

# Calculate variant load per person and apogee-scored variant count per person for all non-synonymous variants
nonsyn_var_apogee_variant_load, nonsyn_var_apogee_count = pathogenic_scoring(dataframe=nonsyn_var_appended,
                                                                             pathogenic_cutoff_value=0.5,
                                                                             pathogenic_col_name='apogee_score')
# Find the number of individuals from each status group who have apogee-scored variants
nonsyn_var_apogee_count_grouped = variant_counts_grouped_by_counts(nonsyn_var_apogee_count, 'pathogenic_count')

# make swarmplot for variant loads: eg.

# create a new figure
plt.figure()

apogee_variant_load_plot = sns.swarmplot(x='status', y='variant_load', data=nonsyn_var_apogee_variant_load)
apogee_variant_load_plot.set_xlabel('Status group', fontsize=12, weight='bold', labelpad=18)
apogee_variant_load_plot.set_xticklabels(['Cases', 'Controls'])
apogee_variant_load_plot.set_ylabel('APOGEE variant load', fontsize=12, weight='bold', labelpad=18)
apogee_variant_load_plot.set_title('APOGEE variant loads per person',
                                   fontsize=14, weight='bold',
                                   pad=18)

# save plot as a .png file
plt.savefig('apogee_variant_load_plot.png', transparent=True, dpi=300, bbox_inches='tight')

# GRAPH: ALL NON-SYNONYMOUS apogee-SCORED VARIANTS >0.5

# create a new figure
plt.figure()

nonsyn_var_apogee_count_grouped_plot = sns.barplot(x='pathogenic_count', y='percentage', hue='status',
                                                   data=nonsyn_var_apogee_count_grouped)
nonsyn_var_apogee_count_grouped_plot.set_xlabel('Count of APOGEE-scored variants', fontsize=12, weight='bold',
                                                labelpad=18)
# nonsyn_var_apogee_count_grouped_plot.set_xticklabels(['Whole mtDNA', 'rRNA genes', 'tRNA genes', 'MDPs', 'non-cdoing', 'OXPHOS genes'])
nonsyn_var_apogee_count_grouped_plot.set_ylabel('Percentage of individuals (%)', fontsize=12, weight='bold',
                                                labelpad=18)
nonsyn_var_apogee_count_grouped_plot.set_title('Percentage of individuals with APOGEE-scored variants >0.5',
                                               fontsize=14, weight='bold',
                                               pad=18)
nonsyn_var_apogee_count_grouped_plot.legend(title='Status group', loc='upper right')
nonsyn_var_apogee_count_grouped_plot = barplot_labels(nonsyn_var_apogee_count_grouped_plot)

# save plot as a .png file
plt.savefig('nonsyn_var_apogee_count_grouped_plot.png', transparent=True, dpi=300, bbox_inches='tight')


# COMMON OUT-OF-PLACE NON-SYNONYMOUS VARIANTS

# Calculate variant load per person and apogee-scored variant count per person for coomon oout-of-place  variants
common_nonsyn_var_apogee_variant_load, common_nonsyn_var_apogee_count = \
    pathogenic_scoring(dataframe=common_nonsyn_var, pathogenic_cutoff_value=0.5, pathogenic_col_name='apogee_score')
# Find the number of individuals from each status group who have rare haplo apogee-scored variants grouped by count
common_nonsyn_var_apogee_count_grouped = variant_counts_grouped_by_counts(common_nonsyn_var_apogee_count,
                                                                              'pathogenic_count')

# OUTPUT FILES FOR USERS
# ----------------------

# OUTPUT FOR GRAPHS

# Make one excel sheet with all the rare variant counts used for graphs

common_var_graphs_dict = {'common_var': common_variants,
                              'common_nonsyn_var': common_nonsyn_variants, 'common_syn_var':
                                  common_syn_variants}
# apply function to save dataframes into one excel file with each df as a separate sheet
save_xls(dict_df=common_var_graphs_dict, path='graph_input.xls')

# VARIANT LOADS OUTPUT
# --------------------

# All variants scored above the pathogencity thresholds
# trim dataframes to only include 2 columns, then add on sample info columns
nonsyn_var_mutpred_variant_load_filter = nonsyn_var_mutpred_variant_load.filter(['sample', 'variant_load'])
nonsyn_var_mutpred_variant_load_filter = nonsyn_var_mutpred_variant_load_filter.merge(sample_info_with_haplogroups, on='sample')
nonsyn_var_mtoolbox_variant_load_filter = nonsyn_var_mtoolbox_variant_load.filter(['sample', 'variant_load'])
nonsyn_var_mtoolbox_variant_load_filter = nonsyn_var_mtoolbox_variant_load_filter.merge(sample_info_with_haplogroups, on='sample')
nonsyn_var_apogee_variant_load_filter = nonsyn_var_apogee_variant_load.filter(['sample', 'variant_load'])
nonsyn_var_apogee_variant_load_filter = nonsyn_var_apogee_variant_load_filter.merge(sample_info_with_haplogroups, on='sample')


# Make one excel sheet with all the variant loads of study participants

variant_load_dict = {'MutPred_variant_loads': nonsyn_var_mutpred_variant_load_filter,
                     'MToolBox_variant_loads': nonsyn_var_mtoolbox_variant_load_filter, 'APOGEE_variant_loads':
                         nonsyn_var_apogee_variant_load_filter}
# The above spreadsheet gives a list of all individuals with a variant/s predicted to be mildy deleterious
# It is not filtered to contain only out-of-place variants

# apply function to save dataframes into one excel file with each df as a separate sheet
save_xls(dict_df=variant_load_dict, path='all_nonsyn_variant_loads_output.xls')

# All common out-of-place variants scored above the pathogencity thresholds

# trim dataframes to only include 2 columns, then add on sample info columns
common_nonsyn_var_mutpred_variant_load_filter = common_nonsyn_var_mutpred_variant_load.filter(['sample', 'variant_load'])
common_nonsyn_var_mutpred_variant_load_filter = common_nonsyn_var_mutpred_variant_load_filter.merge(sample_info_with_haplogroups, on='sample')
common_nonsyn_var_apogee_variant_load_filter = common_nonsyn_var_apogee_variant_load.filter(['sample', 'variant_load'])
common_nonsyn_var_apogee_variant_load_filter= common_nonsyn_var_apogee_variant_load_filter.merge(sample_info_with_haplogroups, on='sample')
common_nonsyn_var_mtoolbox_variant_load_filter = common_nonsyn_var_mtoolbox_variant_load.filter(['sample', 'variant_load'])
common_nonsyn_var_mtoolbox_variant_load_filter = common_nonsyn_var_mtoolbox_variant_load_filter.merge(sample_info_with_haplogroups, on='sample')

# Make one excel file with data on whether or not an individual has one (or more) variant/s scored by a pathogenicity
# scoring algorithm
variant_load_dict = {'OoP_MutPred_var_>0.5': common_nonsyn_var_mutpred_variant_load_filter,
                     'OoP_MToolBox_var_>0.4311': common_nonsyn_var_mtoolbox_variant_load_filter, 'OoP_APOGEE_var_>0.5':
                         common_nonsyn_var_apogee_variant_load_filter}
# apply function to save dataframes into one excel file with each df as a separate sheet
save_xls(dict_df=variant_load_dict, path='OoP_nonsyn_variant_loads_output_output.xls')
# The above spreadsheet gives a list of all individuals with a variant load of variants predicted to be mildy deleterious in their mtDNA
# It is filtered to contain only out-of-place variants


# PATHOGENICITY-SCORED VARIANTS OUTPUT
# ------------------------------------

# All variants scored above the pathogencity thresholds

# trim dataframes to only include 2 columns, then add on sample info columns
nonsyn_var_mutpred_count_filter = nonsyn_var_mutpred_count.filter(['sample', 'pathogenic_count'])
nonsyn_var_mutpred_count_filter = nonsyn_var_mutpred_count_filter.merge(sample_info_with_haplogroups, on='sample')
nonsyn_var_apogee_count_filter = nonsyn_var_apogee_count.filter(['sample', 'pathogenic_count'])
nonsyn_var_apogee_count_filter = nonsyn_var_apogee_count_filter.merge(sample_info_with_haplogroups, on='sample')
nonsyn_var_mtoolbox_count_filter = nonsyn_var_mtoolbox_count.filter(['sample', 'pathogenic_count'])
nonsyn_var_mtoolbox_count_filter = nonsyn_var_mtoolbox_count_filter.merge(sample_info_with_haplogroups, on='sample')

# Make one excel file with data on whether or not an individual has one (or more) variant/s scored by a pathogenicity
# scoring algorithm
variant_load_dict = {'all_MutPred_var_>0.5': nonsyn_var_mutpred_count_filter,
                     'all_MToolBox_var_>0.4311': nonsyn_var_mtoolbox_count_filter, 'all_APOGEE_var_>0.5':
                         nonsyn_var_apogee_count_filter}
# apply function to save dataframes into one excel file with each df as a separate sheet
save_xls(dict_df=variant_load_dict, path='Individual_counts_all_scored_variants_output.xls')
# The above spreadsheet gives a list of all individuals with a count of *all* scored variants predicted to be mildy deleterious in their mtDNA
# It is not filtered to contain only out-of-place variants

# All common out-of-place variants scored above the pathogencity thresholds

# trim dataframes to only include 2 columns, then add on sample info columns
common_nonsyn_var_mutpred_count_filter = common_nonsyn_var_mutpred_count.filter(['sample', 'pathogenic_count'])
common_nonsyn_var_mutpred_count_filter = common_nonsyn_var_mutpred_count_filter.merge(sample_info_with_haplogroups, on='sample')
common_nonsyn_var_apogee_count_filter = common_nonsyn_var_apogee_count.filter(['sample', 'pathogenic_count'])
common_nonsyn_var_apogee_count_filter= common_nonsyn_var_apogee_count_filter.merge(sample_info_with_haplogroups, on='sample')
common_nonsyn_var_mtoolbox_count_filter = common_nonsyn_var_mtoolbox_count.filter(['sample', 'pathogenic_count'])
common_nonsyn_var_mtoolbox_count_filter = common_nonsyn_var_mtoolbox_count_filter.merge(sample_info_with_haplogroups, on='sample')

# Make one excel file with data on whether or not an individual has one (or more) variant/s scored by a pathogenicity
# scoring algorithm
variant_load_dict = {'OoP_MutPred_var_>0.5': common_nonsyn_var_mutpred_count_filter,
                     'OoP_MToolBox_var_>0.4311': common_nonsyn_var_mtoolbox_count_filter, 'OoP_APOGEE_var_>0.5':
                         common_nonsyn_var_apogee_count_filter}
# apply function to save dataframes into one excel file with each df as a separate sheet
save_xls(dict_df=variant_load_dict, path='Individual_counts_OoP_scored_variants_output.xls')
# The above spreadsheet gives a list of all individuals with a count of *out-of-place* scored variants predicted to be mildy deleterious in their mtDNA
# It is filtered to contain only out-of-place variants


# HAPLOGROUPS OUTPUT
# ------------------

# Make one excel sheet with all the haplogroup counts of study participants
haplogroups_dict = {'Samples_excluded_from_analysis': samples_removed,
                    'Haplogroups_per_participant': output_haplogroups,
                    'Simple_haplogroups_count': simple_haplogroups_count,
                    'Mitomaster_haplogroups_count': haplogroups_count}

save_xls(dict_df=haplogroups_dict, path='haplogroup_output.xls')

#  COMMON_OUT OF PLACE  VARIANT COUNTS OUTPUT

# Make one excel sheet with all the common-out-of-place variant counts of study participants
common_count_dict = {'Whole_genome_var_counts': common_mtDNA_var_count,
                     'tRNA_var_counts': common_tRNA_var_count, 'rRNA_var_counts': common_rRNA_var_count,
                     'Noncoding_var_counts': common_noncoding_var_count,
                     'Coding_var_counts': common_coding_var_count,
                     'Synonymous_var_counts': common_syn_var_count,
                     'Synonymous_CI_var_counts': common_syn_CI_var_count,
                     'Synonymous_CIII_var_counts': common_syn_CIII_var_count,
                     'Synonymous_CIV_var_counts': common_syn_CIV_var_count,
                     'Synonymous_CV_var_counts': common_syn_CV_var_count,
                     'Non_synonymous_var_counts': common_nonsyn_var_count,
                     'Non_synonymous_CI_var_counts': common_nonsyn_CI_var_count,
                     'Non_synonymous_CIII_var_counts': common_nonsyn_CIII_var_count,
                     'Non_synonymous_CIV_var_counts': common_nonsyn_CIV_var_count,
                     'Non_synonymous_CV_var_counts': common_nonsyn_CV_var_count,
                     'Non_synonymous_scored_var': common_scored_var_count}

save_xls(dict_df=common_count_dict, path='grouped_variant_counts.xls')


# COMMON OUT OF PLACE FISHER'S EXACT DF

# SCORED COMMON OUT-OF-PLACE VARIANTS

# # make a copy of the dataframe for out-of-place whole genome variants
# common_scored_var = common_mtDNA_var.copy()
#
# # make a new df with common out of place variants that have been scored with one of the three in silico tools as mildy deletrious
# common_scored_var = rare_variants_df(common_scored_var, 'scored_variant', sample_list, sample_info_with_haplogroups)
#
# # calculate count of variants per person
# common_scored_var_count = variant_count(common_scored_var, mtDNA_region='scored_var')
#
# # make df's for fisher's exact test and to make a graph
# common_scored_var_cross_tab, common_scored_var_cross_tab_graph = fishers_exact_df_and_graph_df \
#     (common_scored_var, 'sample_has_common_scored_var', 'scored_var')

def save_xls_fishers(dict_df, path):
    """
    Save a dictionary of dataframes to an excel file, with each dataframe as a separate sheet
    """
    writer = pd.ExcelWriter(path)
    for key in dict_df:
        dict_df[key].to_excel(excel_writer=writer, sheet_name=key, index=True)

    writer.save()


private_var_fishers_dict = {'Whole_genome_var': common_mtDNA_var_cross_tab,
                            'tRNA_var': common_tRNA_var_cross_tab, 'rRNA_var': common_rRNA_var_cross_tab,
                            'Noncoding_var': common_noncoding_var_cross_tab,
                            'Coding_var': common_coding_var_cross_tab,
                            'Synonymous_var': common_syn_var_cross_tab,
                            'Synonymous_CI_var': common_syn_CI_var_cross_tab,
                            'Synonymous_CIII_var': common_syn_CIII_var_cross_tab,
                            'Synonymous_CIV_var': common_syn_CIV_var_cross_tab,
                            'Synonymous_CV_var': common_syn_CV_var_cross_tab,
                            'Non_synonymous_var': common_nonsyn_var_cross_tab,
                            'Non_synonymous_CI_var': common_nonsyn_CI_var_cross_tab,
                            'Non_synonymous_CIII_var': common_nonsyn_CIII_var_cross_tab,
                            'Non_synonymous_CIV_var': common_nonsyn_CIV_var_cross_tab,
                            'Non_synonymous_CV_var': common_nonsyn_CV_var_cross_tab,
                            'Non_synonymous_scored_var': common_scored_var_cross_tab}

save_xls_fishers(dict_df=private_var_fishers_dict, path='Fishers_test_input.xls')

## TODO make a list of novel variants (i.e. genbank freq = 0)


# # PATIENT REPORT OUTPUT
# # ---------------------
#
# # change all 0's to nan
# patient_reports = mitomaster_output.replace(0, np.nan)
# # drop all rows in patient_report col = nan
# patient_reports = patient_reports.dropna(subset=['patient_report'])
# # change all nan's back to 0
# all_patient_reports = patient_reports.replace(np.nan, 0)
# # remove unnecessary columns
# all_patient_reports_trimmed = all_patient_reports.filter(['sample', 'SNP', 'locus', 'conservation%', 'patient_report',
#                                                           'GB_FL_freq%', 'GB_FL_seq', 'haplo_freq%', 'haplo_seq',
#                                                           'rare_haplo', 'rare_GB', 'codon_pos',
#                                                           'AAC', 'MutPred', 'mtoolbox_ds', 'apogee_score', 'age', 'sex',
#                                                           'status', 'haplogroup'])
#
# # make a df with rare haplogroup variant patient reports
#
# rare_haplo_patient_reports = all_patient_reports_trimmed
# # change all 0's to nan
# rare_haplo_patient_reports = all_patient_reports_trimmed.replace(0, np.nan)
# # drop all rows in patient_report col = nan
# rare_haplo_patient_reports = rare_haplo_patient_reports.dropna(subset=['rare_haplo'])
# # change all nan's back to 0
# rare_haplo_patient_reports = rare_haplo_patient_reports.replace(np.nan, 0)
#
# # make a df with rare genbank variant patient reports
#
# rare_GB_patient_reports = all_patient_reports_trimmed
# # change all 0's to nan
# rare_GB_patient_reports = all_patient_reports_trimmed.replace(0, np.nan)
# # drop all rows in patient_report col = nan
# rare_GB_patient_reports = rare_GB_patient_reports.dropna(subset=['rare_GB'])
# # change all nan's back to 0
# rare_GB_patient_reports = rare_GB_patient_reports.replace(np.nan, 0)
#
# # Make one excel sheet with all the variants that have 'patient reports'
# patient_report_dict = {'All_var_patient_reports': all_patient_reports_trimmed,
#                        'Rare_haplo_var_patient_reports': rare_haplo_patient_reports,
#                        'Rare_GB_var_patient_reports': rare_GB_patient_reports}
#
# save_xls(dict_df=patient_report_dict, path='variants_with_patient_reports_output.xls')
#
# ## TODO Check AAC column to make sure it shows whether there is an AAC eg. A563L

# LIST OF COMMON VARIANTS OUTPUT
# ------------------------------

# remove unnecessary columns from common variant df
common_trimmed = common_mtDNA_var.filter(['sample', 'SNP', 'locus', 'conservation%', 'patient_report',
                                                  'GB_FL_freq%', 'GB_FL_seq', 'haplo_freq%', 'haplo_seq',
                                                  'common_var', 'rare_GB', 'codon_pos',
                                                  'AAC', 'MutPred', 'mtoolbox_ds', 'apogee_score', 'age', 'sex',
                                                  'status', 'haplogroup'])


# apply rare_var_counts_grouped_by_SNP function to count the number of individuals with rare variants grouped by the
# SNP and status group
common_var_count = rare_var_counts_grouped_by_SNP(common_trimmed)


# Make one excel sheet with all the variants that are rare
rare_var_dict = {'common_variants': common_trimmed,
                 'common_var_count': common_var_count, }
save_xls(dict_df=rare_var_dict, path='common_out_of_place_variants_output.xls')

 # LIST OF 'UNREPORTED' VARIANTS OUTPUT
# -----------------------------
# make a df with unreported variants (i.e. variants with a '0' int the lit_refs column
unreported_variants = mitomaster_output.filter(['SNP', 'locus', 'conservation%', 'patient_report',
                                            'GB_FL_freq%', 'GB_FL_seq', 'haplo_freq%', 'haplo_seq', 'codon_pos',
                                            'AAC', 'MutPred', 'mtoolbox_ds', 'apogee_score', 'lit_refs',
                                            'sample', 'age', 'sex', 'status', 'haplogrep_haplogroup'])

# Filter for unreported variants
unreported_variants_filter = unreported_variants['lit_refs'] == '0'
unreported_variants.copy()
unreported_variants = unreported_variants[unreported_variants_filter]
# save a file with unreported_variants
unreported_variants.to_excel('unreported_variants.xls', index=False, sheet_name='unreported_variants')

# ----------------------------------------------------------------------------------------------------------------------
# STATISTICAL ANALYSIS
# ---------------------------------------------------------------------------------------------------------------------
# FISHER'S EXACT TEST
# -------------------

# COMMON OUT-OF-PLACE VARIANTS
# ----------------------------

# make a list of dfs to be used for the Fisher's exact tests
common_mtDNA_var_df_list = [common_mtDNA_var_cross_tab, common_tRNA_var_cross_tab, common_rRNA_var_cross_tab,
                            common_noncoding_var_cross_tab, common_coding_var_cross_tab, common_syn_var_cross_tab,
                            common_syn_CI_var_cross_tab,
                            common_syn_CIII_var_cross_tab, common_syn_CIV_var_cross_tab, common_syn_CV_var_cross_tab,
                            common_nonsyn_var_cross_tab,
                            common_nonsyn_CI_var_cross_tab, common_nonsyn_CIII_var_cross_tab,
                            common_nonsyn_CIV_var_cross_tab,
                            common_nonsyn_CV_var_cross_tab, common_scored_var_cross_tab]

# Make a list of names for the corresponding dfs

Fisher_test_DataFrame_list_scored = ['Whole_genome', 'tRNA', 'rRNA', 'Non-coding', 'Coding',
                              'Synonymous', 'Synonymous_CI', 'Synonymous_CIII',
                              'Synonymous_CIV', 'Synonymous_CV', 'Non_synonymous', 'Non_synonymous_CI',
                              'Non_synonymous_CIII',
                              'Non_synonymous_CIV', 'Non_synonymous_CV', 'Non_synonymous_scored']

# apply fishers exact function
common_mtDNA_var_fishers_tests = fishers_test(df_list=common_mtDNA_var_df_list, row_list=Fisher_test_DataFrame_list_scored)


# save fishers exact output as xlsx file
common_mtDNA_var_fishers_tests.to_excel("Fishers_test_output.xlsx", index = False)

## TEST
input_df_list = [nonsyn_CI_var, nonsyn_CIII_var, nonsyn_CV_var, nonsyn_CV_var]
df_names_list = ['common_nonsyn_CI_var','common_nonsyn_CIII_var', 'common_nonsyn_CV_var', 'common_nonsyn_CV_var']

new_df_list = [rare_variants_df(i,'common_var', sample_list, sample_info) for i in input_df_list]
# Create a zip object from two lists
zipbObj = zip(df_names_list, new_df_list)
# Create a dictionary from zip object
dictOfDfs = dict(zipbObj)
print(dictOfDfs)

# ----------------------------------------------------------------------------------------------------------------------
# USER MESSAGE: ANALYSIS COMPLETE
# ---------------------------------------------------------------------------------------------------------------------

print('Analysis successfully completed!')

os.chdir(r'C:\Users\Mi\Projects\mtDNA_NGS\NGS_scripts')
easygui.msgbox(msg="SUCCESS!! \n\n" "Your data has been analysed and your output files been saved!",
               title='Files saved successfully')
